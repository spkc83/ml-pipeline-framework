{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Engine Testing and Optimization\n",
    "\n",
    "This notebook demonstrates pandas performance characteristics, memory optimization techniques, and best practices for CSV processing in the ML Pipeline Framework.\n",
    "\n",
    "## Topics Covered:\n",
    "- 📊 CSV data loading with pandas\n",
    "- 💾 Memory usage profiling and optimization\n",
    "- ⏱️ Performance benchmarks for common operations\n",
    "- 🔧 Chunked processing for large datasets\n",
    "- 🎯 Optimization techniques (categorical dtypes, etc.)\n",
    "- 📈 Scalability analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport psutil\nimport os\nimport sys\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Add project root to path\nsys.path.insert(0, os.path.abspath('..'))\n\n# ML Pipeline Framework imports - basic ones only\nfrom src.utils.logging_config import setup_logging\n\n# Configure plotting\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\nprint(f\"Pandas version: {pd.__version__}\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"System memory: {psutil.virtual_memory().total / 1024**3:.1f} GB\")\nprint(f\"Available memory: {psutil.virtual_memory().available / 1024**3:.1f} GB\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_data(n_rows=100000, save_path=None):\n",
    "    \"\"\"Generate realistic test data for performance testing.\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate data with different data types\n",
    "    data = {\n",
    "        # Integer columns (different ranges for dtype optimization testing)\n",
    "        'id': range(n_rows),\n",
    "        'small_int': np.random.randint(0, 100, n_rows),  # Can be uint8\n",
    "        'medium_int': np.random.randint(0, 10000, n_rows),  # Can be uint16\n",
    "        'large_int': np.random.randint(0, 1000000, n_rows),  # uint32\n",
    "        \n",
    "        # Float columns\n",
    "        'price': np.random.lognormal(4, 1, n_rows),  # Price-like distribution\n",
    "        'score': np.random.normal(75, 15, n_rows),  # Score with normal distribution\n",
    "        'ratio': np.random.beta(2, 5, n_rows),  # Ratio between 0-1\n",
    "        \n",
    "        # String columns (different cardinalities)\n",
    "        'category_high': np.random.choice(['A', 'B', 'C'], n_rows),  # Low cardinality - good for categorical\n",
    "        'category_medium': np.random.choice([f'Cat_{i}' for i in range(50)], n_rows),  # Medium cardinality\n",
    "        'category_low': np.random.choice([f'Item_{i}' for i in range(n_rows//10)], n_rows),  # High cardinality\n",
    "        \n",
    "        # Boolean column\n",
    "        'is_active': np.random.choice([True, False], n_rows),\n",
    "        \n",
    "        # Date column\n",
    "        'created_date': pd.date_range('2020-01-01', periods=n_rows, freq='H'),\n",
    "        \n",
    "        # Text column\n",
    "        'description': [f'Description for item {i} with some text content' for i in range(n_rows)]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add some missing values\n",
    "    missing_cols = ['score', 'description', 'category_medium']\n",
    "    for col in missing_cols:\n",
    "        missing_indices = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)\n",
    "        df.loc[missing_indices, col] = np.nan\n",
    "    \n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        df.to_csv(save_path, index=False)\n",
    "        print(f\"Test data saved to {save_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate test datasets of different sizes\n",
    "test_sizes = [10000, 50000, 100000, 500000]\n",
    "test_files = {}\n",
    "\n",
    "for size in test_sizes:\n",
    "    file_path = f'../data/test_data_{size}.csv'\n",
    "    test_files[size] = file_path\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Generating test data with {size:,} rows...\")\n",
    "        df = generate_test_data(size, file_path)\n",
    "    else:\n",
    "        print(f\"Test data with {size:,} rows already exists\")\n",
    "\n",
    "print(\"\\nTest files created:\")\n",
    "for size, path in test_files.items():\n",
    "    file_size = os.path.getsize(path) / 1024**2\n",
    "    print(f\"  {size:,} rows: {path} ({file_size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_memory_usage(df, title=\"DataFrame Memory Analysis\"):\n",
    "    \"\"\"Comprehensive memory usage analysis.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * len(title))\n",
    "    \n",
    "    # Overall memory usage\n",
    "    total_memory = df.memory_usage(deep=True).sum()\n",
    "    print(f\"Total memory usage: {total_memory / 1024**2:.2f} MB\")\n",
    "    print(f\"Rows: {len(df):,}, Columns: {len(df.columns)}\")\n",
    "    print(f\"Memory per row: {total_memory / len(df):.1f} bytes\")\n",
    "    \n",
    "    # Memory usage by column\n",
    "    memory_usage = df.memory_usage(deep=True)\n",
    "    memory_df = pd.DataFrame({\n",
    "        'Column': ['Index'] + df.columns.tolist(),\n",
    "        'Memory_MB': memory_usage / 1024**2,\n",
    "        'Memory_Percentage': (memory_usage / total_memory) * 100,\n",
    "        'Dtype': ['Index'] + [str(dtype) for dtype in df.dtypes]\n",
    "    })\n",
    "    \n",
    "    memory_df = memory_df.sort_values('Memory_MB', ascending=False)\n",
    "    \n",
    "    print(\"\\nMemory usage by column:\")\n",
    "    print(memory_df.to_string(index=False, float_format='%.2f'))\n",
    "    \n",
    "    return memory_df\n",
    "\n",
    "# Load and analyze a sample dataset\n",
    "sample_df = pd.read_csv(test_files[100000])\n",
    "memory_analysis = analyze_memory_usage(sample_df, \"Original Data Memory Usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Type Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_dtypes(df):\n",
    "    \"\"\"Optimize data types for memory efficiency.\"\"\"\n",
    "    \n",
    "    optimized_df = df.copy()\n",
    "    \n",
    "    print(\"Optimizing data types...\")\n",
    "    \n",
    "    for col in optimized_df.columns:\n",
    "        col_type = optimized_df[col].dtype\n",
    "        \n",
    "        # Skip datetime columns\n",
    "        if pd.api.types.is_datetime64_any_dtype(optimized_df[col]):\n",
    "            continue\n",
    "        \n",
    "        # Optimize integers\n",
    "        if pd.api.types.is_integer_dtype(optimized_df[col]):\n",
    "            min_val = optimized_df[col].min()\n",
    "            max_val = optimized_df[col].max()\n",
    "            \n",
    "            if min_val >= 0:  # Unsigned integers\n",
    "                if max_val < 255:\n",
    "                    optimized_df[col] = optimized_df[col].astype('uint8')\n",
    "                elif max_val < 65535:\n",
    "                    optimized_df[col] = optimized_df[col].astype('uint16')\n",
    "                elif max_val < 4294967295:\n",
    "                    optimized_df[col] = optimized_df[col].astype('uint32')\n",
    "            else:  # Signed integers\n",
    "                if min_val >= -128 and max_val < 128:\n",
    "                    optimized_df[col] = optimized_df[col].astype('int8')\n",
    "                elif min_val >= -32768 and max_val < 32768:\n",
    "                    optimized_df[col] = optimized_df[col].astype('int16')\n",
    "                elif min_val >= -2147483648 and max_val < 2147483648:\n",
    "                    optimized_df[col] = optimized_df[col].astype('int32')\n",
    "        \n",
    "        # Optimize floats\n",
    "        elif pd.api.types.is_float_dtype(optimized_df[col]):\n",
    "            optimized_df[col] = pd.to_numeric(optimized_df[col], downcast='float')\n",
    "        \n",
    "        # Convert to categorical for low cardinality strings\n",
    "        elif pd.api.types.is_object_dtype(optimized_df[col]):\n",
    "            if optimized_df[col].notna().sum() > 0:  # Skip if all NaN\n",
    "                unique_count = optimized_df[col].nunique()\n",
    "                total_count = len(optimized_df[col])\n",
    "                \n",
    "                # Convert to categorical if less than 50% unique values and < 1000 categories\n",
    "                if unique_count / total_count < 0.5 and unique_count < 1000:\n",
    "                    optimized_df[col] = optimized_df[col].astype('category')\n",
    "                    print(f\"  {col}: object -> category ({unique_count} categories)\")\n",
    "    \n",
    "    return optimized_df\n",
    "\n",
    "# Optimize the sample dataset\n",
    "optimized_df = optimize_dtypes(sample_df)\n",
    "optimized_memory = analyze_memory_usage(optimized_df, \"Optimized Data Memory Usage\")\n",
    "\n",
    "# Calculate memory savings\n",
    "original_memory = sample_df.memory_usage(deep=True).sum()\n",
    "new_memory = optimized_df.memory_usage(deep=True).sum()\n",
    "savings = (original_memory - new_memory) / original_memory * 100\n",
    "\n",
    "print(f\"\\n📊 Memory Optimization Results:\")\n",
    "print(f\"Original memory: {original_memory / 1024**2:.2f} MB\")\n",
    "print(f\"Optimized memory: {new_memory / 1024**2:.2f} MB\")\n",
    "print(f\"Memory savings: {savings:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_operation(df, operation_name, operation_func, *args, **kwargs):\n",
    "    \"\"\"Benchmark a pandas operation.\"\"\"\n",
    "    \n",
    "    # Get initial memory usage\n",
    "    process = psutil.Process()\n",
    "    initial_memory = process.memory_info().rss / 1024**2\n",
    "    \n",
    "    # Time the operation\n",
    "    start_time = time.time()\n",
    "    result = operation_func(df, *args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Get peak memory usage\n",
    "    peak_memory = process.memory_info().rss / 1024**2\n",
    "    memory_used = peak_memory - initial_memory\n",
    "    \n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    return {\n",
    "        'operation': operation_name,\n",
    "        'duration_seconds': duration,\n",
    "        'memory_used_mb': memory_used,\n",
    "        'rows_processed': len(df),\n",
    "        'rows_per_second': len(df) / duration if duration > 0 else float('inf')\n",
    "    }\n",
    "\n",
    "# Define benchmark operations\n",
    "def groupby_operation(df):\n",
    "    return df.groupby('category_high')['price'].agg(['mean', 'sum', 'count'])\n",
    "\n",
    "def join_operation(df):\n",
    "    # Self join for demonstration\n",
    "    lookup_df = df[['id', 'category_high']].head(1000)\n",
    "    return df.merge(lookup_df, on='id', how='left', suffixes=('', '_lookup'))\n",
    "\n",
    "def aggregation_operation(df):\n",
    "    return df.agg({\n",
    "        'price': ['mean', 'std', 'min', 'max'],\n",
    "        'score': ['mean', 'median'],\n",
    "        'small_int': 'sum'\n",
    "    })\n",
    "\n",
    "def filter_operation(df):\n",
    "    return df[(df['price'] > df['price'].quantile(0.5)) & (df['is_active'] == True)]\n",
    "\n",
    "def sort_operation(df):\n",
    "    return df.sort_values(['price', 'score'], ascending=[False, True])\n",
    "\n",
    "# Run benchmarks on different dataset sizes\n",
    "benchmark_results = []\n",
    "operations = [\n",
    "    ('GroupBy', groupby_operation),\n",
    "    ('Join', join_operation),\n",
    "    ('Aggregation', aggregation_operation),\n",
    "    ('Filter', filter_operation),\n",
    "    ('Sort', sort_operation)\n",
    "]\n",
    "\n",
    "print(\"Running performance benchmarks...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "for size in [10000, 50000, 100000][:2]:  # Limit to smaller sizes for demo\n",
    "    print(f\"Benchmarking with {size:,} rows...\")\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(test_files[size])\n",
    "    \n",
    "    # Optimize dtypes\n",
    "    df_optimized = optimize_dtypes(df)\n",
    "    \n",
    "    for op_name, op_func in operations:\n",
    "        try:\n",
    "            # Benchmark original dataframe\n",
    "            result_orig = benchmark_operation(df, f\"{op_name}_Original\", op_func)\n",
    "            result_orig['dataset_size'] = size\n",
    "            result_orig['optimization'] = 'Original'\n",
    "            benchmark_results.append(result_orig)\n",
    "            \n",
    "            # Benchmark optimized dataframe\n",
    "            result_opt = benchmark_operation(df_optimized, f\"{op_name}_Optimized\", op_func)\n",
    "            result_opt['dataset_size'] = size\n",
    "            result_opt['optimization'] = 'Optimized'\n",
    "            benchmark_results.append(result_opt)\n",
    "            \n",
    "            print(f\"  {op_name}: {result_orig['duration_seconds']:.3f}s -> {result_opt['duration_seconds']:.3f}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  {op_name}: Error - {e}\")\n",
    "\n",
    "# Convert results to DataFrame for analysis\n",
    "benchmark_df = pd.DataFrame(benchmark_results)\n",
    "print(\"\\n📊 Benchmark Results Summary:\")\n",
    "print(benchmark_df.groupby(['operation', 'optimization'])['duration_seconds'].mean().unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunked Processing Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_in_chunks(file_path, chunk_size=10000, operation_func=None):\n",
    "    \"\"\"Demonstrate chunked processing for large CSV files.\"\"\"\n",
    "    \n",
    "    print(f\"Processing {file_path} in chunks of {chunk_size:,} rows...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    chunk_count = 0\n",
    "    total_rows = 0\n",
    "    results = []\n",
    "    \n",
    "    # Process in chunks\n",
    "    chunk_reader = pd.read_csv(file_path, chunksize=chunk_size)\n",
    "    \n",
    "    for chunk in chunk_reader:\n",
    "        chunk_count += 1\n",
    "        total_rows += len(chunk)\n",
    "        \n",
    "        # Apply operation to chunk if provided\n",
    "        if operation_func:\n",
    "            chunk_result = operation_func(chunk)\n",
    "            results.append(chunk_result)\n",
    "        \n",
    "        # Memory monitoring\n",
    "        if chunk_count % 10 == 0:\n",
    "            memory_usage = psutil.Process().memory_info().rss / 1024**2\n",
    "            print(f\"  Processed {chunk_count} chunks ({total_rows:,} rows), Memory: {memory_usage:.1f} MB\")\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    print(f\"✅ Completed: {chunk_count} chunks, {total_rows:,} total rows in {duration:.2f}s\")\n",
    "    print(f\"   Throughput: {total_rows/duration:,.0f} rows/second\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Calculate summary statistics using chunked processing\n",
    "def chunk_summary_stats(chunk):\n",
    "    \"\"\"Calculate summary statistics for a chunk.\"\"\"\n",
    "    return {\n",
    "        'row_count': len(chunk),\n",
    "        'price_mean': chunk['price'].mean(),\n",
    "        'price_sum': chunk['price'].sum(),\n",
    "        'active_count': chunk['is_active'].sum()\n",
    "    }\n",
    "\n",
    "# Test chunked processing\n",
    "chunk_results = process_csv_in_chunks(\n",
    "    test_files[100000], \n",
    "    chunk_size=5000, \n",
    "    operation_func=chunk_summary_stats\n",
    ")\n",
    "\n",
    "# Aggregate results from all chunks\n",
    "if chunk_results:\n",
    "    total_rows = sum(r['row_count'] for r in chunk_results)\n",
    "    weighted_price_mean = sum(r['price_mean'] * r['row_count'] for r in chunk_results) / total_rows\n",
    "    total_price_sum = sum(r['price_sum'] for r in chunk_results)\n",
    "    total_active = sum(r['active_count'] for r in chunk_results)\n",
    "    \n",
    "    print(f\"\\n📈 Aggregated Results:\")\n",
    "    print(f\"Total rows processed: {total_rows:,}\")\n",
    "    print(f\"Average price: ${weighted_price_mean:.2f}\")\n",
    "    print(f\"Total price sum: ${total_price_sum:,.2f}\")\n",
    "    print(f\"Active records: {total_active:,} ({total_active/total_rows*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Connector Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test basic CSV processing since advanced CSV connector may not be available\ncsv_config = {\n    'file_paths': [test_files[50000]],\n    'chunk_size': 10000,\n    'optimize_dtypes': True,\n    'validate_headers': True\n}\n\nprint(\"Testing CSV processing with pandas...\")\n\n# Basic CSV operations\nfile_path = test_files[50000]\nprint(f\"File path: {file_path}\")\n\n# Get file info manually\nfile_size = os.path.getsize(file_path) / 1024**2\nprint(f\"File size: {file_size:.1f} MB\")\n\n# Load data using pandas directly\nstart_time = time.time()\ndf_test = pd.read_csv(file_path)\nload_time = time.time() - start_time\n\nprint(f\"\\n📊 Data loaded:\")\nprint(f\"  Rows: {len(df_test):,}\")\nprint(f\"  Columns: {len(df_test.columns)}\")\nprint(f\"  Memory: {df_test.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\nprint(f\"  Load time: {load_time:.3f}s\")\n\n# Test chunked reading manually\nprint(\"\\nTesting chunked reading...\")\nchunk_count = 0\nchunk_size = 5000\n\nfor chunk in pd.read_csv(file_path, chunksize=chunk_size):\n    chunk_count += 1\n    if chunk_count <= 3:  # Show first 3 chunks\n        print(f\"  Chunk {chunk_count}: {len(chunk)} rows, {chunk.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n    elif chunk_count == 4:\n        print(\"  ...\")\n    if chunk_count >= 10:  # Limit for demo\n        break\n\nprint(f\"Processed {chunk_count} chunks\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how pandas performance scales with data size\n",
    "scalability_results = []\n",
    "\n",
    "print(\"Analyzing pandas scalability...\")\n",
    "\n",
    "for size in [10000, 50000, 100000]:\n",
    "    print(f\"\\nTesting with {size:,} rows...\")\n",
    "    \n",
    "    # Load data\n",
    "    start_time = time.time()\n",
    "    df = pd.read_csv(test_files[size])\n",
    "    load_time = time.time() - start_time\n",
    "    \n",
    "    # Memory usage\n",
    "    memory_mb = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    \n",
    "    # Simple operations timing\n",
    "    ops_start = time.time()\n",
    "    \n",
    "    # Basic operations\n",
    "    summary = df.describe()\n",
    "    filtered = df[df['price'] > df['price'].median()]\n",
    "    grouped = df.groupby('category_high')['price'].mean()\n",
    "    \n",
    "    ops_time = time.time() - ops_start\n",
    "    \n",
    "    result = {\n",
    "        'rows': size,\n",
    "        'load_time': load_time,\n",
    "        'memory_mb': memory_mb,\n",
    "        'operations_time': ops_time,\n",
    "        'memory_per_row': memory_mb / size * 1024,  # KB per row\n",
    "        'load_throughput': size / load_time\n",
    "    }\n",
    "    \n",
    "    scalability_results.append(result)\n",
    "    \n",
    "    print(f\"  Load time: {load_time:.3f}s ({size/load_time:,.0f} rows/s)\")\n",
    "    print(f\"  Memory usage: {memory_mb:.1f} MB ({memory_mb/size*1024:.1f} KB/row)\")\n",
    "    print(f\"  Operations time: {ops_time:.3f}s\")\n",
    "\n",
    "# Create scalability DataFrame\n",
    "scalability_df = pd.DataFrame(scalability_results)\n",
    "\n",
    "print(\"\\n📈 Scalability Analysis:\")\n",
    "print(scalability_df.to_string(index=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Pandas Performance Analysis', fontsize=16)\n",
    "\n",
    "# 1. Memory usage vs dataset size\n",
    "axes[0, 0].plot(scalability_df['rows'], scalability_df['memory_mb'], 'o-', linewidth=2, markersize=8)\n",
    "axes[0, 0].set_xlabel('Number of Rows')\n",
    "axes[0, 0].set_ylabel('Memory Usage (MB)')\n",
    "axes[0, 0].set_title('Memory Usage vs Dataset Size')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Load throughput vs dataset size\n",
    "axes[0, 1].plot(scalability_df['rows'], scalability_df['load_throughput'], 's-', \n",
    "                color='orange', linewidth=2, markersize=8)\n",
    "axes[0, 1].set_xlabel('Number of Rows')\n",
    "axes[0, 1].set_ylabel('Load Throughput (rows/second)')\n",
    "axes[0, 1].set_title('CSV Load Throughput')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Memory efficiency (KB per row)\n",
    "axes[1, 0].bar(range(len(scalability_df)), scalability_df['memory_per_row'], \n",
    "               color='green', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Dataset Size')\n",
    "axes[1, 0].set_ylabel('Memory per Row (KB)')\n",
    "axes[1, 0].set_title('Memory Efficiency')\n",
    "axes[1, 0].set_xticks(range(len(scalability_df)))\n",
    "axes[1, 0].set_xticklabels([f\"{int(rows/1000)}K\" for rows in scalability_df['rows']])\n",
    "\n",
    "# 4. Operations performance comparison\n",
    "if benchmark_results:\n",
    "    benchmark_summary = pd.DataFrame(benchmark_results)\n",
    "    \n",
    "    # Group by operation and optimization\n",
    "    perf_comparison = benchmark_summary.groupby(['operation', 'optimization'])['duration_seconds'].mean().unstack()\n",
    "    \n",
    "    if not perf_comparison.empty:\n",
    "        perf_comparison.plot(kind='bar', ax=axes[1, 1], alpha=0.8)\n",
    "        axes[1, 1].set_xlabel('Operation')\n",
    "        axes[1, 1].set_ylabel('Duration (seconds)')\n",
    "        axes[1, 1].set_title('Performance: Original vs Optimized')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        axes[1, 1].legend(title='Data Types')\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'No benchmark data available', ha='center', va='center')\n",
    "        axes[1, 1].set_title('Performance Comparison')\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'No benchmark data available', ha='center', va='center')\n",
    "    axes[1, 1].set_title('Performance Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Memory optimization visualization\n",
    "if 'memory_analysis' in locals() and 'optimized_memory' in locals():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Before optimization\n",
    "    memory_analysis_viz = memory_analysis[memory_analysis['Column'] != 'Index'].head(10)\n",
    "    ax1.barh(memory_analysis_viz['Column'], memory_analysis_viz['Memory_MB'])\n",
    "    ax1.set_xlabel('Memory Usage (MB)')\n",
    "    ax1.set_title('Memory Usage by Column (Original)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # After optimization\n",
    "    optimized_memory_viz = optimized_memory[optimized_memory['Column'] != 'Index'].head(10)\n",
    "    ax2.barh(optimized_memory_viz['Column'], optimized_memory_viz['Memory_MB'], color='green')\n",
    "    ax2.set_xlabel('Memory Usage (MB)')\n",
    "    ax2.set_title('Memory Usage by Column (Optimized)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🎯 PANDAS OPTIMIZATION BEST PRACTICES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. DATA TYPE OPTIMIZATION:\")\n",
    "print(\"   • Use smallest possible integer types (int8, int16, uint8, uint16)\")\n",
    "print(\"   • Convert float64 to float32 when precision allows\")\n",
    "print(\"   • Use categorical dtype for low-cardinality string columns\")\n",
    "print(\"   • Convert boolean-like strings to actual boolean type\")\n",
    "\n",
    "print(\"\\n2. MEMORY MANAGEMENT:\")\n",
    "print(\"   • Monitor memory usage with df.memory_usage(deep=True)\")\n",
    "print(\"   • Use chunked processing for files > available memory\")\n",
    "print(\"   • Delete intermediate DataFrames when not needed\")\n",
    "print(\"   • Consider using copy=False for views when safe\")\n",
    "\n",
    "print(\"\\n3. PERFORMANCE OPTIMIZATION:\")\n",
    "print(\"   • Use vectorized operations instead of loops\")\n",
    "print(\"   • Leverage pandas' built-in functions (groupby, merge, etc.)\")\n",
    "print(\"   • Set categorical columns before groupby operations\")\n",
    "print(\"   • Use appropriate chunk sizes (10K-100K rows typically optimal)\")\n",
    "\n",
    "print(\"\\n4. CSV READING OPTIMIZATION:\")\n",
    "print(\"   • Specify dtypes explicitly to avoid inference overhead\")\n",
    "print(\"   • Use parse_dates for known date columns\")\n",
    "print(\"   • Consider usecols to read only needed columns\")\n",
    "print(\"   • Use compression (gzip, zip) for storage and I/O efficiency\")\n",
    "\n",
    "print(\"\\n5. WHEN TO CONSIDER ALTERNATIVES:\")\n",
    "print(\"   • Data > 5GB: Consider Polars or DuckDB\")\n",
    "print(\"   • Complex SQL-like operations: Consider DuckDB\")\n",
    "print(\"   • Need lazy evaluation: Consider Polars\")\n",
    "print(\"   • Distributed processing: Consider PySpark\")\n",
    "\n",
    "# Performance summary based on our tests\n",
    "if scalability_results:\n",
    "    avg_load_speed = np.mean([r['load_throughput'] for r in scalability_results])\n",
    "    avg_memory_per_row = np.mean([r['memory_per_row'] for r in scalability_results])\n",
    "    \n",
    "    print(f\"\\n📊 PERFORMANCE SUMMARY (This System):\")\n",
    "    print(f\"   • Average CSV load speed: {avg_load_speed:,.0f} rows/second\")\n",
    "    print(f\"   • Average memory per row: {avg_memory_per_row:.1f} KB\")\n",
    "    print(f\"   • Recommended chunk size: {10000:,} - {50000:,} rows\")\n",
    "    \n",
    "    if savings and 'savings' in locals():\n",
    "        print(f\"   • Memory optimization savings: {savings:.1f}%\")\n",
    "\n",
    "print(\"\\n✅ Pandas engine analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}