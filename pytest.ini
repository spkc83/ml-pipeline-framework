[tool:pytest]
# pytest configuration for ML Pipeline Framework

# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Markers
markers =
    unit: Unit tests
    integration: Integration tests
    e2e: End-to-end tests
    spark: Tests that require Spark
    slow: Slow-running tests
    gpu: Tests that require GPU
    external: Tests that require external services
    performance: Performance/benchmark tests

# Output and reporting
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --durations=10
    --color=yes
    --disable-warnings

# Coverage
# Note: Coverage settings can also be configured here
# --cov=src
# --cov-report=term-missing
# --cov-report=html:reports/coverage_html
# --cov-report=xml:reports/coverage.xml
# --cov-fail-under=80

# Filtering
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning:sklearn.*
    ignore::DeprecationWarning:pandas.*
    ignore::PendingDeprecationWarning
    ignore::FutureWarning:sklearn.*

# Timeouts (requires pytest-timeout)
timeout = 300
timeout_method = thread

# Parallel execution (requires pytest-xdist)
# Use with: pytest -n auto
# addopts = -n auto

# Test order randomization (requires pytest-randomly)
# addopts = --randomly-seed=42

# Minimum version requirements
minversion = 6.0

# Log configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/logs/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)d)
log_file_date_format = %Y-%m-%d %H:%M:%S

# xfail behavior
xfail_strict = true

# Test collection
collect_ignore = [
    "setup.py",
    "conftest.py"
]

# Console output
console_output_style = progress